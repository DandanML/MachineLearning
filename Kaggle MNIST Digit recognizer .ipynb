{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping, CSVLogger, ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234) #set a randomseed so that the results can be repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's first load the training data and understand the training data for both input and output.\n",
    "# the data file can be downloaded from kaggle website: https://www.kaggle.com/c/digit-recognizer/data\n",
    "training_data = pd.read_csv('MNISTI_train.csv')\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "training_data.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Training data shows that we have 42000 samples, and each sample has 1 labeled output and 784 features as input. In the following, we need to \n",
    "separate the training input and output. Also, need to check whether the output is a multi-class or binary class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate training data input and output.\n",
    "X_train = training_data.drop(['label'], axis=1)\n",
    "Y_train = training_data['label']\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    4\n",
       "4    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    42000.000000\n",
       "mean         4.456643\n",
       "std          2.887730\n",
       "min          0.000000\n",
       "25%          2.000000\n",
       "50%          4.000000\n",
       "75%          7.000000\n",
       "max          9.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the output statistics\n",
    "Y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJKmLwSFJ6vL/AevWFc82x5mAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21dc0055f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "g=sns.countplot(Y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from the above display: X_train has 42000, and Y_train has 42000. and No missing data in X_train nor Y_train. and Output ranges from 0 to 9. Thus, this is a multiclass classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since keras model is dealing with numpy array, let's convert dataframe into numpy array. note that it has been change into float32. \n",
    "# This is mainly for speeding up training on GPU. Meanwhile, the resolution is more than enough:-). \n",
    "X_train_val = X_train.values.astype('float32')\n",
    "Y_train_val = Y_train.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_val.shape\n",
    "Y_train_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21d803384a8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21d8013df60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#since this is image, let's take a look at the input image first.\n",
    "# we have 784 pixel, thus 784=28x28. only one channel.\n",
    "X_display = X_train_val[0].reshape(28,28)\n",
    "plt.imshow(X_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21d884b70b8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCD+QFOEHkiL8QFKEH0jq/wEGdtT4efqESQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21d80312358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#the above image is in color. If we want to display it in gray.\n",
    "plt.imshow(X_display, cmap='gray')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In the following, we will start the training using CNN model using Keras sequential model. Keras functional API provides more flexibility in terms of concatate models. but it is not really needed here since we will use a simple multiple layer CNN model. (LeNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a CNN model\n",
    "def cnn_model(input_shape, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(5,5), padding='same', strides=(2,2),\n",
    "                    activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Conv2D(32,kernel_size=(5,5), padding='same', activation='relu', strides=(2,2)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we need to reshape the input to the input shape required by CNN model.\n",
    "# as recall, the X_train_val is with shape of (42000, 784). It needs to be changed into (42000, 28, 28, 1), basically (# of samples, PixelX, PixelY, #of channels)\n",
    "# in this case, # of channel is 1. \n",
    "# we have two way to reshape, we can either specify the number of samples (get it from X_train_val.shape[0]) or using reshape(-1, 28, 28,1)\n",
    "# also, note that we do not split the training into training and validation manually. Instead we will use the validation_split option in kears.model.fit argument.\n",
    "Pixel = int(math.sqrt(X_train_val.shape[1])) #instead of using 28, we get 28 from the intput shape to avoid hard code number.\n",
    "X_train_val = X_train_val.reshape(-1, Pixel, Pixel, 1)\n",
    "input_shape = (Pixel, Pixel,1) # the input shape of CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#double check the shape\n",
    "X_train_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's process the labeled output. For a multiclass classification, we will need to change into one-hot vector and also loss function is\n",
    "# categorial_crossentropy. For multilabel classification, the loss function is binary_crossentropy. \n",
    "# if the output is not numbers from 0 to 9, we generally need to convert it into numbers. and then do one-hot transform.\n",
    "encoder = LabelEncoder() \n",
    "encoder.fit(Y_train_val)\n",
    "encoder_class_filename ='MNIST_encoder_class.npy'\n",
    "np.save(encoder_class_filename, encoder.classes_) # this is to save the encoder class. It is useful when we saved the model and then use the model on separate testing data.\n",
    "encoded_y_train = encoder.transform(Y_train_val)\n",
    "# the above four steps are not needed in this case as the output is from 0 to 9.\n",
    "dummy_y_train = np_utils.to_categorical(encoded_y_train)\n",
    "output_dim = dummy_y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 30,922\n",
      "Trainable params: 30,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_model(input_shape, output_dim)\n",
    "num_parameter = model.count_params() # this is to count how many parameter in this model.\n",
    "print(model.summary()) # this one gives the layout of the model. very useful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/200\n",
      " - 13s - loss: 3.3855 - acc: 0.2595 - val_loss: 1.4590 - val_acc: 0.5219\n",
      "Epoch 2/200\n",
      " - 12s - loss: 1.0322 - acc: 0.6561 - val_loss: 0.3994 - val_acc: 0.8921\n",
      "Epoch 3/200\n",
      " - 12s - loss: 0.4583 - acc: 0.8510 - val_loss: 0.2274 - val_acc: 0.9312\n",
      "Epoch 4/200\n",
      " - 12s - loss: 0.2940 - acc: 0.9070 - val_loss: 0.1676 - val_acc: 0.9500\n",
      "Epoch 5/200\n",
      " - 12s - loss: 0.2350 - acc: 0.9255 - val_loss: 0.1459 - val_acc: 0.9581\n",
      "Epoch 6/200\n",
      " - 12s - loss: 0.1884 - acc: 0.9404 - val_loss: 0.1366 - val_acc: 0.9586\n",
      "Epoch 7/200\n",
      " - 12s - loss: 0.1606 - acc: 0.9505 - val_loss: 0.1127 - val_acc: 0.9657\n",
      "Epoch 8/200\n",
      " - 12s - loss: 0.1413 - acc: 0.9558 - val_loss: 0.1079 - val_acc: 0.9681\n",
      "Epoch 9/200\n",
      " - 13s - loss: 0.1218 - acc: 0.9627 - val_loss: 0.1031 - val_acc: 0.9700\n",
      "Epoch 10/200\n",
      " - 12s - loss: 0.1101 - acc: 0.9660 - val_loss: 0.0960 - val_acc: 0.9721\n",
      "Epoch 11/200\n",
      " - 12s - loss: 0.0991 - acc: 0.9697 - val_loss: 0.0853 - val_acc: 0.9738\n",
      "Epoch 12/200\n",
      " - 13s - loss: 0.0897 - acc: 0.9715 - val_loss: 0.0942 - val_acc: 0.9736\n",
      "Epoch 13/200\n",
      " - 13s - loss: 0.0842 - acc: 0.9733 - val_loss: 0.0772 - val_acc: 0.9748\n",
      "Epoch 14/200\n",
      " - 13s - loss: 0.0776 - acc: 0.9753 - val_loss: 0.0837 - val_acc: 0.9771\n",
      "Epoch 15/200\n",
      " - 12s - loss: 0.0712 - acc: 0.9767 - val_loss: 0.0773 - val_acc: 0.9781\n",
      "Epoch 16/200\n",
      " - 12s - loss: 0.0645 - acc: 0.9789 - val_loss: 0.0786 - val_acc: 0.9774\n",
      "Epoch 17/200\n",
      " - 13s - loss: 0.0631 - acc: 0.9794 - val_loss: 0.0725 - val_acc: 0.9776\n",
      "Epoch 18/200\n",
      " - 13s - loss: 0.0580 - acc: 0.9816 - val_loss: 0.0612 - val_acc: 0.9817\n",
      "Epoch 19/200\n",
      " - 12s - loss: 0.0516 - acc: 0.9836 - val_loss: 0.0688 - val_acc: 0.9824\n",
      "Epoch 20/200\n",
      " - 12s - loss: 0.0526 - acc: 0.9831 - val_loss: 0.0652 - val_acc: 0.9800\n",
      "Epoch 21/200\n",
      " - 12s - loss: 0.0479 - acc: 0.9841 - val_loss: 0.0704 - val_acc: 0.9798\n",
      "Epoch 22/200\n",
      " - 12s - loss: 0.0450 - acc: 0.9853 - val_loss: 0.0624 - val_acc: 0.9812\n",
      "Epoch 23/200\n",
      " - 12s - loss: 0.0437 - acc: 0.9848 - val_loss: 0.0573 - val_acc: 0.9840\n",
      "Epoch 24/200\n",
      " - 13s - loss: 0.0387 - acc: 0.9877 - val_loss: 0.0633 - val_acc: 0.9824\n",
      "Epoch 25/200\n",
      " - 13s - loss: 0.0399 - acc: 0.9872 - val_loss: 0.0675 - val_acc: 0.9817\n",
      "Epoch 26/200\n",
      " - 12s - loss: 0.0354 - acc: 0.9883 - val_loss: 0.0601 - val_acc: 0.9845\n",
      "Epoch 27/200\n",
      " - 13s - loss: 0.0378 - acc: 0.9879 - val_loss: 0.0561 - val_acc: 0.9845\n",
      "Epoch 28/200\n",
      " - 12s - loss: 0.0331 - acc: 0.9893 - val_loss: 0.0599 - val_acc: 0.9824\n",
      "Epoch 29/200\n",
      " - 15s - loss: 0.0309 - acc: 0.9899 - val_loss: 0.0587 - val_acc: 0.9845\n",
      "Epoch 30/200\n",
      " - 12s - loss: 0.0322 - acc: 0.9895 - val_loss: 0.0610 - val_acc: 0.9845\n",
      "Epoch 31/200\n",
      " - 12s - loss: 0.0305 - acc: 0.9896 - val_loss: 0.0617 - val_acc: 0.9840\n",
      "Epoch 32/200\n",
      " - 13s - loss: 0.0333 - acc: 0.9890 - val_loss: 0.0637 - val_acc: 0.9833\n",
      "Epoch 33/200\n",
      " - 12s - loss: 0.0284 - acc: 0.9909 - val_loss: 0.0568 - val_acc: 0.9850\n",
      "Epoch 34/200\n",
      " - 13s - loss: 0.0319 - acc: 0.9893 - val_loss: 0.0626 - val_acc: 0.9850\n",
      "Epoch 35/200\n",
      " - 13s - loss: 0.0277 - acc: 0.9908 - val_loss: 0.0634 - val_acc: 0.9840\n",
      "Epoch 36/200\n",
      " - 13s - loss: 0.0297 - acc: 0.9902 - val_loss: 0.0628 - val_acc: 0.9857\n",
      "Epoch 37/200\n",
      " - 12s - loss: 0.0258 - acc: 0.9919 - val_loss: 0.0647 - val_acc: 0.9838\n",
      "Epoch 00037: early stopping\n",
      "time took 463.7295475886806econds to train the model\n",
      "Saved the best model weights into disk:  MNIST_model_weight_filename.json\n",
      "saved model to disk in file:  MNIST_model_filename.h5\n",
      "saved training log to disk in file:  MNIST_training_log.csv\n"
     ]
    }
   ],
   "source": [
    "log_filename = 'MNIST_training_log.csv'\n",
    "model_filename = 'MNIST_model_filename.h5'\n",
    "model_weight_filename = 'MNIST_model_weight_filename.json'\n",
    "tic = time.clock()\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=10, verbose=2, mode='auto')\n",
    "csv_logger = CSVLogger(log_filename, append=False, separator=',')\n",
    "checkpoint = ModelCheckpoint(model_weight_filename, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "callbacks_list = [early_stop, csv_logger, checkpoint]\n",
    "print(\"Training start\")\n",
    "model.fit(X_train_val, dummy_y_train, epochs=200, batch_size=512, validation_split=0.1, validation_data=None, callbacks=callbacks_list, verbose=2, shuffle=True)\n",
    "toc = time.clock()\n",
    "print(\"time took % seconds to train the model\" %(toc-tic))\n",
    "print(\"Saved the best model weights into disk: \", model_weight_filename)\n",
    "# save the model itself\n",
    "model_json = model.to_json()\n",
    "with open(model_filename, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "print(\"saved model to disk in file: \", model_filename)\n",
    "print(\"saved training log to disk in file: \", log_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since the above results without regularization shows training accuracy is higher than the validation accuracy(0.9999 vs. 0.9786), this is overfitting. Add dropout for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the following, we will evaluate the model performance using testing data.\n",
    "# let's first load the testing data.\n",
    "test_data = pd.read_csv('MNIST_test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28000 entries, 0 to 27999\n",
      "Columns: 784 entries, pixel0 to pixel783\n",
      "dtypes: int64(784)\n",
      "memory usage: 167.5 MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 28, 28, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are 28000 samples to be tested. \n",
    "#preprocessing the test data into the format matching to the input of CNN model.\n",
    "test_data_val = test_data.values.astype('float32')\n",
    "PixelNum = int(math.sqrt(test_data_val.shape[1]))\n",
    "test_data_val = test_data_val.reshape(-1, PixelNum, PixelNum, 1)\n",
    "test_data_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading saved model\n",
      "Loaded model from disk\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 30,922\n",
      "Trainable params: 30,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    " print(\"\\nLoading saved model\")\n",
    " model_filename = 'MNIST_model_filename.h5'\n",
    " model_weight_filename = 'MNIST_model_weight_filename.json'\n",
    " # load json and create model\n",
    " json_file = open(model_filename, 'r')\n",
    " loaded_model_json = json_file.read()\n",
    " json_file.close()\n",
    " loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    " loaded_model.load_weights(model_weight_filename)\n",
    " print(\"Loaded model from disk\")\n",
    " print(loaded_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = loaded_model.predict(test_data_val)\n",
    "predicted_y_test_val = np.argmax(predicted_y_test, axis=1)\n",
    "encoder_class_filename ='MNIST_encoder_class.npy'\n",
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = np.load(encoder_class_filename)\n",
    "predicted_y_labeled = encoder.inverse_transform(predicted_y_test_val)\n",
    "predicted_y_labeled = predicted_y_labeled.astype('int') # Watch Out for the output format: it should be in integer instead of float "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.Series(predicted_y_labeled, name='Label')\n",
    "final_submission = pd.concat([pd.Series(range(1, predicted_y_labeled.shape[0]+1), name='ImageId'), results], axis=1)\n",
    "final_submission.to_csv('MNIST_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21d8977b908>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0ERfiAowg8E9f/Izh8yMbT1pwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21d898e1080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_data_val[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
